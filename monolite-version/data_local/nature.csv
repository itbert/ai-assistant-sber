Заголовок,Время публикации,Описание,Ссылка
Audio long read: Do smartphones and social media really harm teens’ mental health?,25 APR 2025,,https://www.nature.com/articles/d41586-025-01310-w
Hundreds more NSF grants terminated after agency director resigns,25 APR 2025,"Sethuraman Panchanathan resigned Thursday as director of the US National Science Foundation.Credit: Graeme Sloan/Sipa US/Alamy
Fresh turmoil has hit the US National Science Foundation (NSF): hundreds more of the agency’s research grants were terminated today on top of the hundreds already terminated last week, Nature has learnt. The new terminations come one day after the agency’s director abruptly resigned and NSF staff members were offered incentives to retire early due to “future restructuring, staffing reductions, and constrained budget environments”.
The departing director, Sethuraman Panchanathan, was appointed as head of one of the world’s leading funders of basic research by US President Donald Trump in 2019 during his first term in office.
NSF slashes prestigious PhD fellowship awards by half
But Trump, now in office for a second time, allegedly wants to cut the agency’s US$9-billion budget by 55% and its workforce by 50%, according to Science. In a farewell letter to staff, Panchanathan wrote, “I believe that I have done all I can to advance the mission of the agency”, adding, “while NSF has always been an efficient agency, we still took the challenge of identifying other possible efficiencies”.
Nature spoke with seven NSF staff members for this story. All requested anonymity because they are not authorized to speak with the press. Staffers said they were stunned by Panchanathan’s sudden departure. “I respect him more for deciding to resign and not signing the agency’s death warrant,” says one NSF staffer.
Neal Lane, a former NSF director under Democratic president Bill Clinton, offered praise for Panchanathan, who goes by ‘Panch’. “Panch has done an outstanding job” amid the effort to “diminish NSF’s role in science, education and pretty much everything else”, Lane says. The US National Science Board, which governs the NSF, praised Panchanathan in a statement as “fantastic”.
Asked for comment, an NSF spokesperson referred Nature to Panchanathan’s farewell letter. The spokesperson said that Brian Stone, the NSF’s chief of staff, will serve as director until the White House appoints a permanent replacement and the US Senate confirms them. The White House Office of Science and Technology Policy, which oversees the NSF, did not respond to a request for comment.
Crisis mode
Since Trump, a Republican, took office, the NSF has frozen and unfrozen grants, fired and rehired employees and cut its graduate research fellowship programme from about 2,000 positions to 1,000. The latest bout of upheaval began on 17 April, when NSF staff members were given guidance for receiving “VIP visitors” from the Department of Governmental Efficiency (DOGE), an initiative led by Trump ally Elon Musk to reduce federal spending and shrink the federal workforce.
Exclusive: Trump team freezes new NSF awards — and could soon axe hundreds of grants
The guidance said that in the event of a request that “violates or doesn’t follow proper procedures”, employees were to contact Dorothy Aronson, the NSF’s chief information officer. “Do not give any indication that the request will be denied,” the guidance statement noted. Two members of DOGE, Luke Farritor and Zachary Terrell, were quickly given complete access to NSF grant-management systems despite statements in the guidance to staffers that they should initially receive read-only access. The guidance to NSF employees was first reported by FedScoop, a government technology media publication, and confirmed by Nature.
On 18 April, after the arrival of three DOGE staffers at NSF headquarters in Alexandria, Virginia, the agency halted the funding of any new research grants for a week. The agency has now started issuing the grants again, but has issued only 377 for April, compared with 863 in April last year.
The same day, the NSF began terminating research grants that had already been awarded, apparently under orders from DOGE. An internal list obtained by Nature shows that the NSF has axed at least 387 awards worth $237 million, of which roughly 45% has already been spent. Over one-third of these, or 152 grants, had been awarded by the NSF’s directorate of education. The numbers match crowdsourced data compiled in an online database by Scott Delaney, an epidemiologist at the Harvard T. H. Chan School of Public Health in Cambridge, Massachusetts, and Noam Ross, a computational ecologist based in Brooklyn, New York, who is executive director of rOpensci, an open-science, global non-profit.
About 80% of these terminated awards overlap with a list of around 3,500 grants released in February by Ted Cruz, a Republican senator from Texas who chairs the US Senate Committee on Commerce, Science, and Transportation. The list stems from a Cruz-led report saying that the grants ‘promoted Diversity, Equity and Inclusion (DEI)’, a concept that it suggests is “extremist”. Last week, an analysis by Democratic staff for the US House of Representatives’ Committee on Science, Space, and Technology, found that the Cruz list contained a “slew of embarrassing mistakes” and used flawed methodology.
Sudden end",https://www.nature.com/articles/d41586-025-01312-8
Huge reproducibility project fails to validate dozens of biomedical studies,25 APR 2025,"A replication drive focused on results that lean on three methods commonly used in biomedical research in Brazil. Credit: Mauro Pimentel/AFP/Getty
In an unprecedented effort, a coalition of more than 50 research teams has surveyed a swathe of Brazilian biomedical studies to double-check their findings — with dismaying results.
The teams were able to replicate the results of less than half of the tested experiments1. That rate is in keeping with that found by other large-scale attempts to reproduce scientific findings. But the latest work is unique in focusing on papers that use specific methods and in examining the research output of a specific country, according to the research teams.
The results provide an impetus to strengthen the country’s science, the study’s authors say. “We now have the material to start making changes from within — whether through public policies or within universities,” says Mariana Boechat de Abreu, a metascience researcher at the Federal University of Rio de Janeiro (UFRJ) in Brazil and one of the coordinators of the project.
The work was posted on 8 April to the bioRxiv preprint server and has not yet been peer reviewed.
Ambitious undertaking
The massive experiment was coordinated by the Brazilian Reproducibility Initiative, a collaborative effort launched in 2019 by researchers at the UFRJ. The scientists wanted to assess publications “based on methods, rather than research area, perceived importance or citation counts”, de Abreu says. And they wanted to do so on a large scale. Ultimately, 213 scientists at 56 laboratories in Brazil were involved in the work.
The project unfolded during the COVID-19 pandemic, which brought numerous logistical challenges. And teams disagreed about how closely to follow the tested protocols. “It was like trying to turn dozens of garage bands, each with its own way of playing, into an orchestra,” says project coordinator Olavo Bohrer Amaral, a physician at the UFRJ.
Reproducibility trial: 246 biologists get different results from same data sets
The authors began by reviewing a random sample of life-sciences articles to determine the most common biomedical research methods used in Brazil, ensuring that any biomedical lab interested in joining the project would be capable of reproducing the experiments.
They ended up selecting three of these methods: an assay of cell metabolism, a technique for amplifying genetic material and a type of maze test for rodents. Then the authors randomly selected biomedical papers that relied on those methods and were published from 1998 to 2017 by research teams in which at least half the contributors had a Brazilian affiliation.
The collaborators initially chose a subset of 60 papers for replication, guided by factors such as whether a paper included certain statistical information. Three labs tested each experiment, and an independent committee judged which of those tests was a valid replication. The coalition performed 97 valid replication attempts of 47 experiments.
Falling short
The authors judged a paper’s replicability by five criteria, including whether at least half of the replication attempts had statistically significant results in the same direction as the original paper. Only 21% of the experiments were replicable using at least half of the applicable criteria.
The authors also found that the effect size — the magnitude of the observed impact in the experiments — was, on average, 60% larger in the original papers than in the experimental follow-ups, indicating that published results tend to overestimate the effects of the interventions tested.",https://www.nature.com/articles/d41586-025-01266-x
Science sleuths flag hundreds of papers that use AI without disclosing it,24 APR 2025,"Credit: Laurence Dutton/Getty
“As of my last knowledge update”, “regenerate response”, “as an AI language model” — these are just a few of the telltale signs of researchers’ use of artificial intelligence (AI) that science-integrity watchers have found sprinkled through papers in the scholarly literature.
Three ways ChatGPT helps me in my academic writing
Generative AI tools such as ChatGPT have quickly transformed academic publishing. Scientists are increasingly using them to prepare and review manuscripts, and publishers have scrambled to create guidelines for their ethical use. Although policies vary, many publishers require authors to disclose the use of AI in the preparation of scientific papers.
But science sleuths have identified hundreds of cases in which AI tools seem to have been used without disclosure. In some cases, the papers have been silently corrected — the hallmark AI phrases removed without acknowledgement. This type of quiet change is a potential threat to scientific integrity, say some researchers.
Such changes have appeared in a “small minority of journals”, says Alex Glynn, a research literacy and communications instructor at the University of Louisville in Kentucky. But given that there are probably also many cases in which authors have used AI without leaving obvious signs, “I am surprised by how much there is”, he adds.
‘I am an AI language model’
Since 2023, integrity specialists have flagged papers with obvious signs of undisclosed AI use, such as those that contain the phrase “regenerate response”, generated by some chatbots based on large language models when a user wants a new answer to a query. Such phrases can appear in articles when an author copies and pastes a chatbot’s responses.
Scientific sleuths spot dishonest ChatGPT use in papers
One of the first cases that Glynn recalls seeing was in a now-retracted paper published in 2024 in Radiology Case Reports1 that contained the chatbot phrase “I am an AI language model”. “It was as blatant as it could possibly be,” Glynn says. “Somehow this passed not only the authors’ eyes, but the editors, reviewers, typesetters and everyone else who was involved in the production process.”
Glynn has since found hundreds more papers with hallmarks of AI use — including some containing subtler signs, such as the words, “Certainly, here are”, another phrase typical of AI chatbots. He created an online tracker, Academ-AI, to log these cases — and has more than 700 papers listed. In an analysis of the first 500 papers flagged, released as a preprint in November2, Glynn found that 13% of these articles appeared in journals belonging to large publishers, such as Elsevier, Springer Nature and MDPI.
Artur Strzelecki, a researcher at the University of Economics in Katowice, Poland, has also gathered examples of undisclosed AI use in papers, focusing on reputable journals. In a study published in December, he identified 64 papers that were published in journals categorized by the Scopus academic database as being in the top quartile for their field3. “These are places where we’d expect good work from editors and decent reviews,” Strzelecki says.
‘Obviously ChatGPT’ — how reviewers accused me of scientific fraud
Nature’s news team contacted several publishers whose papers had been flagged by Glynn and Strzelecki, including Springer Nature, Taylor & Francis and IEEE. (Nature’s news team is editorially independent of its publisher, Springer Nature.) All said that the flagged papers are under investigation. They also pointed to their AI policies — which, in some cases, do not require disclosure of AI use or require it only for certain uses. Springer (owned by Springer Nature), for example, states that AI-assisted copy editing, which includes changes made for readability, style, and grammar or spelling errors, need not be flagged.
Kim Eggleton, head of peer review and research integrity at IOP Publishing in Bristol, UK, notes that although the publisher introduced a policy requiring authors to declare AI use in 2023, it changed the rules last year to reflect the ubiquity of the tools. “While we encourage authors to disclose the use of AI, it is no longer mandated,” Eggleton says. “We are focusing on ensuring the accuracy and robustness of the content through a combination of automated and human checks, rather than prohibiting AI completely.” IOP’s policy does, however, prohibit the use of AI to “create, alter or manipulate” research data or results.",https://www.nature.com/articles/d41586-025-01180-2
How Trump’s attack on universities is putting research in peril,24 APR 2025,"Harvard University in Cambridge, Massachusetts, is being targeted by the administration of US President Donald Trump in its bid to reshape higher education.Credit: Sophie Park/Getty
A test for lead contamination in water, a project to measure the oldest light in the Universe and a study of heat and drought’s effects on the brain are all on ice after US President Donald Trump’s administration halted research grants to several elite US universities.
US science-funding agencies have so far frozen or cancelled at least US$6 billion in research grants and contracts across a number of top universities (see ‘Science stalled’) as part of the Trump administration’s fight to reshape admissions, teaching and more at these institutions. Such actions have been justified in various ways, or not at all.
The Trump administration has alleged that both Columbia University in New York City, and Harvard University in Cambridge, Massachusetts, failed to stop “antisemitic violence and harassment” on their campuses during protests over the war in Gaza. Funding at the University of Pennsylvania (UPenn) in Philadelphia was halted, with the Trump team citing a transgender athlete who swam on the institution’s women’s team in 2022 (Trump issued an executive order on 20 January saying that such activities deprive women of “dignity, safety, and well-being”.) The reasons for funding freezes at Cornell University in Ithaca, New York, Princeton University in New Jersey and Northwestern University in Evanston, Illinois, have not been communicated publicly.
Source: Data from Trump administration announcements, media reports and NIH RePORT
The Trump team has sent demands to Harvard and Columbia, such as orders to instil more-rigorous student discipline, which it says they must meet to restore funding. Columbia initially yielded, but Harvard did not, and is now suing the administration. More than 200 university presidents have since signed a letter opposing “unprecedented government overreach”.
Trump and his Republican allies have long alleged that elite universities are indoctrinating their students with left-wing ideologies. The president signed an executive order yesterday requiring accreditors — whose evaluations determine whether US institutions can receive federal funds — to prioritize “intellectual diversity” at universities. Scientists are now caught in the crosshairs, as the Trump administration uses federal grants as leverage in its fight.
The White House did not respond to Nature’s request for comment.
Labs on the brink
Last September, the US National Institutes of Health (NIH) awarded epidemiologist Marianthi-Anna Kioumourtzoglou’s team at Columbia a 3-year, $4.2-million grant to investigate the potential impacts of co-occurring natural disasters such as heat, drought and wildfires on brain function. On 10 March, she was told that the grant had been terminated.
More than six weeks later, Kioumourtzoglou’s pay remains steady, but her graduate students have lost their income and one of her postdocs stands to lose their funding after June. Kioumourtzoglou has participated in faculty protests calling on Columbia’s leaders to stand up to the Trump administration. “If we lose academic freedom and freedom of speech, what does research even mean?” she asks.
How Trump 2.0 is slashing NIH-backed research — in charts
Kioumourtzoglou hails from Greece and has thought about leaving the United States, but she isn’t ready to give up. “Someone has to stay and fight,” she says. “If we all start leaving, then who’s left?”
Some laboratories are already being shut down because of the cuts. When Trump came into office, about 15 people, including political scientist Heather Huntington, worked in a development-research lab at UPenn. They studied topics such as education, governance and land use in low-income countries with the goal of fostering sustainable development. Now, after the termination of several million dollars in grants to the lab from the US Department of Defense (DoD) and other agencies, the lab is winding down.
Huntington has already had to terminate several positions and rescind job offers. By the end of August, she says, only two people will be left, including herself. It’s hard to make sense of the decision to cut the funding, she says. “It’s such a small percentage of the US budget, and it’s not going to show up in anyone’s tax bill,” she adds. “And yet the ramifications are immense.”
The DoD and NIH did not respond to Nature’s request for comment before this story was published.
No explanation
Julius Lucks, a chemical and biological engineer at Northwestern, wants to give people safer water in their homes. He has been developing a simple test, which relies on microorganisms’ innate ability to detect lead and can quickly catch contamination in water flowing from lead pipes. The project has been rolling out across Chicago, Illinois, where residents can put drops of their tap water onto Lucks’s test kits to see whether it’s safe to drink. But, on 9 April, he and his colleagues received notice from their funder, the DoD, to stop work on the project immediately. They were not told why their research was put on hold.
In many cases, scientists have received little to no communication from the administration. “They just said ‘we’ve basically stopped this grant, and you have to stop working on it today’,” says David Muller, a physicist at Cornell. Three of his DoD grants have been frozen for weeks without explanation.
These US labs risk imminent closure after Trump cuts",https://www.nature.com/articles/d41586-025-01289-4
Major European institutes join race to save US science data,24 APR 2025,"Several research institutes in Germany are joining a worldwide grass-roots effort to save science data sets that researchers fear could be deleted or decommissioned on the orders of US President Donald Trump’s administration, Nature has learnt.
‘Totally broken’: how Trump 2.0 has paralysed work at US science agencies
An official with Pangaea, a massive environmental data repository run by the University of Bremen and the Alfred Wegener Institute in Bremerhaven, says that the organization is formally working with the US National Oceanic and Atmospheric Administration (NOAA) to back up at-risk databases. Pangaea’s decision to join the cause followed distress calls from members of the science community and from staff members inside NOAA — an agency that monitors Earth’s atmosphere and climate and provides weather-forecasting services. The Trump administration has promised to slash government spending and has proposed to gut NOAA’s climate research programmes, which administration officials have said promote “exaggerated and implausible climate threats”.
Earlier this month, media outlets including Bloomberg reported that access to various agency databases would end within days because the administration wanted to cancel contracts with Amazon Web Services, which hosts NOAA’s data online. The cancellation has since been postponed — but the news sent fear through the research community.
After Trump was elected last year, Eric Nost, a geographer at the University of Guelph in Ontario, Canada, and other volunteers began backing up US data, worried about the information disappearing. Trump 2.0 has lived up to expectations, Nost says, by endangering various kinds of data. But he adds that the situation at NOAA represents the first major threat to core data sets that are crucial for all kinds of environmental research. One scientist who was recently fired from the agency confirmed to Nature that the websites in question include data sets used in active weather-forecasting operations. “If those were to go out, it would be really bad,” says the scientist, who asked to remain anonymous because they fear retaliation while seeking new employment.
NOAA officials did not respond to requests for comment regarding the agency’s work with Pangaea or other statements in this article.
Rescue operation
Pangaea is part of the Helmholtz Association of German Research Centres, which is joining the effort to save US data. The Helmholtz campaign has already expanded to include saving toxicology databases at the US Environmental Protection Agency (EPA). “The idea is to bring five or six institutes together to create a data-rescue package,” says Frank Oliver Glöckner, a bioinformatician who leads Pangaea. “But we must do this officially: we don’t want to steal data. We want to save data.”
(Researchers who are working to safeguard information emphasize that the government data is freely available to download and use.)
Five key climate and space projects on Trump’s chopping block
An EPA spokesperson declined to answer questions regarding efforts to safeguard toxicology databases, but said that the agency is “actively listening to employees at all levels to gather ideas on how to better fulfil agency statutory obligations, increase efficiency and ensure the EPA is as up-to-date and effective as ever”.
Whenever a new president takes office, websites are altered and information moved around as government employees respond to the incoming administration’s priorities. Efforts to preserve old information have been going on for nearly two decades. However, fears of actually losing scientific data came to the fore during Trump’s first presidency, from 2017 to 2021, after agencies including the EPA began taking down websites related to climate and other subjects.",https://www.nature.com/articles/d41586-025-01309-3
Baffling chronic pain eases after doses of gut microbes,24 APR 2025,"The micro-organisms living in the human gut can affect many biological functions, including pain perception.Credit: Steve Gschmeissner/Science Photo Library
What Rina Green calls her “living hell” began with an innocuous backache. By late 2022, two years later, pain flooded her entire body daily and could be so intense that she couldn’t get out of bed. Painkillers and physical therapy offered little relief. She began using a wheelchair.
Green has fibromyalgia, a mysterious condition with symptoms of widespread and chronic muscle pain and fatigue. No one knows why people get fibromyalgia, and it is difficult to treat. But eight months ago, Green received an experimental therapy: pills containing living microorganisms of the kind that populate the healthy human gut. Her pain decreased substantially, and Green, who lives in Haifa, Israel, and is now 38, can go on walks — something she hadn’t done since her fibromyalgia diagnosis.
Green was one of 14 participants in a trial of microbial supplements for the condition. All but two reported an improvement in their symptoms. The trial is so small that “we should take the results with a grain of salt”, says co-organizer Amir Minerbi, a pain scientist at the Technion — Israel Institute of Technology in Haifa. “But it is encouraging [enough] to move forward.” The trial results and data from other experiments linking fibromyalgia to gut microbes are published today in Neuron1.
Pain-inducing microbes
Fibromyalgia affects up to 4% of the global population and occurs in the absence of tissue damage. In 2019, Minerbi and his colleagues discovered that the gut microbiomes — the collection of microbes living in the intestines — of women with fibromyalgia differed significantly from those of healthy women2. This led the scientists to wonder whether a dose of microbes from healthy people would ease the pain and fatigue caused by the condition. After all, previous research3 had shown that gut microbes might indirectly influence an array of chemical signals tied to pain perception.
How pain is misunderstood and ignored in women
The team transplanted minuscule samples of microbe-laden faeces from both women with fibromyalgia and healthy women into mice without any microbes in their bodies. The researchers found that mice that received microbes from women with fibromyalgia showed signs of greater sensitivity to pain in response to pressure, heat and cold than did mice that got microbes from healthy women. The first group also showed more evidence of spontaneous pain.
The team next transplanted faeces from healthy women into mice that had been colonized with fibromyalgia-associated microbes and then treated with antibiotics. These mice showed reduced symptoms of pain after the transplant. Mice that received both transplants but didn’t get antibiotics showed no improvement.
The researchers then conducted a trial with 14 women, including Green, who had severe, treatment-resistant fibromyalgia. All the participants received antibiotics and then, over ten weeks, regularly swallowed capsules containing gut bacteria from healthy women. Twelve reported improvement in symptoms such as pain, anxiety and sleep disturbances. Fatigue was a common side effect of the treatment.
The researchers note that gut microbes from people with fibromyalgia might prompt the immune system to attack neural circuits that are involved in pain. The microbes also metabolize compounds secreted by the human liver into molecules that can affect pain sensitivity.",https://www.nature.com/articles/d41586-025-01290-x
How Democrats and Republicans cite science: study reveals stark differences,24 APR 2025,"How US lawmakers cite scientific papers differs either side of the aisle.Credit: Saul Loeb/AFP via Getty
The United States is known for the deep polarization between its two major political parties — the right-wing Republicans and left-wing Democrats. Now an analysis of hundreds of thousands of policy documents reveals striking differences in partisan policymakers’ use of the scientific literature, with Democratic-led congressional committees and left-wing think tanks more likely to cite research papers than their right-wing counterparts.
Has your research influenced policy? Use this free tool to check
The analysis also shows that Democrats and left-leaning think tanks are more likely to cite high-impact research, and that the two political sides rarely cite the same studies or even the same topics.
“There are striking differences in amount, content and character of the science cited by partisan policymakers,” says Alexander Furnas, a political scientist at Northwestern University in Evanston, Illinois, and a co-author of the analysis, published1 in Science on 24 April.
The researchers used the government-policy database Overton to assemble around 50,000 policy documents produced by US congressional committees in 1995–2021 and around 200,000 reports from 121 ideologically driven US think tanks over a similar period. These documents contained 424,000 scientific references.
Source: Ref. 1
A statistical analysis revealed that congressional reports are now more likely to cite science papers than before. But, in each two-year congressional cycle, documents from committees under Democratic control had a higher probability of citing research papers, and the gap between the two parties has increased (see ‘Science in the US Congress’). Overall, documents from Democratic-controlled committees were nearly 1.8 times more likely to cite science than were reports from Republican-led ones.",https://www.nature.com/articles/d41586-025-01311-9
"A brand-new colour created by lasers, a pig-liver transplant trial gets the green light, and a nugget-sized chunk of lab-grown meat",23 APR 2025,,https://www.nature.com/articles/d41586-025-01288-5
Three ways to cool Earth by pulling carbon from the sky,23 APR 2025,"Sometime in the next several months, a team of US scientists plans to pour a solution of antacid into the waves off the coast of Massachusetts. Using boats, buoys and autonomous gliders, the scientists will track changes in water chemistry that should allow this tiny patch of the Atlantic Ocean to absorb more carbon dioxide from the sky than it normally would.
The US$10-million experiment, dubbed LOC-NESS, aims to test one prominent strategy to reverse global warming by removing CO2 from the atmosphere. Doing so will be neither cheap nor easy. But with the world looking likely to blow past the temperature targets laid out in the 2015 Paris climate agreement, a growing number of scientists and policy specialists say that carbon removal will be necessary later this century if humanity is to achieve its long-term climate goals.
Earth breaches 1.5 °C climate limit for the first time: what does it mean?
Governments, utility companies and hundreds of start-up organizations around the globe are now investing billions of dollars in carbon-removal strategies that take three broad approaches: sucking carbon directly from the air; altering the oceans to absorb more carbon than normal; and enhancing carbon removal on land. In the United States, for example, companies are planning to build several large-scale ‘direct air capture’ facilities that scrub CO2 out of thin air. And in Europe, power companies are developing a strategy that captures carbon emissions from bioenergy plants that burn woodchips, straw and other plant-based materials: the captured CO2 will then be pumped into the ground beneath the North Sea. Many companies are already selling voluntary carbon-removal credits to organizations such as Microsoft and Google to help them meet their climate commitments. By some estimates, the world might need to remove more than 6 billion tonnes of CO2 from the atmosphere each year by mid-century to meet its long-term climate goals(see ‘Catching carbon’)1.
Source: IEA (go.nature.com/4CAV8A9)
If such approaches succeed, these technologies could help many nations and corporations to meet their climate commitments — and help the world to halt global warming. But the carbon-removal industry faces stiff headwinds, owing in part to a lack of international standards for such technologies and formal commitments by governments. Another major hurdle is a political sea change under US President Donald Trump: the United States had been the largest government backer of research and development for carbon-removal technologies, but Trump is now scaling back climate and clean-energy investments. Most importantly, say researchers, there are also scientific questions about whether the budding market for carbon removal and the technologies can live up to the hype.
This is where academic research projects, such as LOC-NESS, come into play, as a way to test carbon-removal strategies in real-world settings. Although the basic science behind this type of ocean experiment is sound, researchers aren’t sure how it will work in practice. The details matter, says Adam Subhas, a geochemist at the Woods Hole Oceanographic Institution in Massachusetts, who is heading up the four-year LOC-NESS project. “There’s all sorts of activity in the private sector,” Subhas says, “and it’s really critical that the science keeps pace.”
Pulling carbon from the air
The cheapest way to draw carbon out of the atmosphere is to grow more forests, but trees are not necessarily a permanent solution because they might be cut down or burn in fires, which are a growing threat. Many scientists and industrialists therefore focus on more permanent — and more expensive — solutions.
The simplest method is industrial-scale direct air capture, but it’s also the most expensive, costing in the region of $600–$1,000 per tonne of CO2, which is roughly 10 times higher than the price of carbon credits on the European Union Emissions Trading System.
Pulling carbon from the sky is necessary but not sufficient
What will become the world’s largest direct-air-capture facility is expected to start operations later this year in west Texas as a joint operation between two companies: Houston-based Occidental Petroleum and Carbon Engineering in Squamish, Canada. The consortium plans to bury the 500,000 tonnes of CO2 captured each year underground. The group is also developing a second facility as part of a direct-air-capture ‘hub’ that received a $600-million grant commitment from the US Department of Energy (DOE) under former president Joe Biden in 2023. Another $600-million commitment from the DOE went to a second air-capture hub in Louisiana, which features a pair of facilities that will use technology from Heirloom Carbon Technologies, a firm in Brisbane, California, and a Swiss company called Climeworks based in Zurich that operates what is currently the world’s largest direct-air-capture facility, in Iceland.
Both of the DOE hubs will pump the carbon they extract from the atmosphere underground. With funding from an infrastructure law passed by Congress in 2021, the DOE had planned to invest another $2.3 billion in other air-capture projects. But since Trump took office, the DOE has frozen funding for that programme, including money committed to the plants in Texas and Louisiana. It remains unclear whether or when the agency will fulfil even its existing grant commitments, which many specialists fear will threaten the viability of both hubs.
At a plant in Squamish, Canada, the firm Carbon Engineering tests carbon-capture technology.Credit: James MacDonald/Bloomberg/Getty
“We don’t actually know whether the Trump administration will honour these contracts, even though they are legally binding,” says a person who worked in carbon removal at the DOE before being fired alongside roughly 2,000 other probationary employees in February. “It puts a lot of these projects in a really risky place,” says the former DOE employee who declined to be named because of concerns over potential retribution.
Others fear that the Trump administration will take further steps that slow advances in this area, such as freezing funding that was set aside for the purchase of carbon-removal credits on behalf of the US government. There are also concerns that the administration could dismantle an interagency effort dubbed the Carbon Negative Shot, which aims to scale-up technologies and reduce the cost of carbon removal to below $100 per tonne by 2032. The government could have played an important part in advancing research and development, as well as promoting the creation of common standards for an industry that currently operates like the Wild West, says Wil Burns, co-director of the Institute for Carbon Removal Law and Policy at American University in Washington DC. But those efforts “are being swept away” by the new administration, adds Burns. The DOE did not respond to a request to comment from Nature.
Ocean alchemy
One project that seems to be moving forwards for now is LOC-NESS, which has received support through a $24-million public–private research programme coordinated by the US National Oceanic and Atmospheric Administration (NOAA). In August, assuming that the final permits come through, Subhas and his team will release a solution containing 50 tonnes of sodium hydroxide (which is not used as an antacid for humans) alongside an inert tracer dye roughly 60 kilometres off the coast of Provincetown, Massachusetts. The researchers will then monitor the solution as it disperses, reducing the acidity of seawater and enabling it to absorb more CO2 from the atmosphere.
In theory, Subhas says, the biological effects will mostly be minor and positive2, but monitoring during the experiment should help the team to assess potential impacts on shell-building organisms such as phytoplankton and diatoms. Studies using computer modelling suggest that during the week-long field experiment, the researchers should be able to measure how much CO2 is absorbed by the ocean as a result of their intervention.
Start-ups are adding antacids to the ocean to slow global warming. Will it work?
If the team can show that it is possible to monitor and quantify how much extra CO2 is absorbed, the potential for scaling up is significant: with even a small increase in alkalinity, Subhas says, coastal countries around the world could collectively extract one billion tonnes of CO2 from the atmosphere each year, which is roughly equivalent to the annual carbon emissions from Japan and is about 3% of global emissions. Cost estimates vary widely for appoaches that depend on altering ocean chemistry to absorb carbon, but most suggest that they are likely to be cheaper than direct air capture3.
LOC-NESS is just one of 17 projects funded through the NOAA research programme, and so far those efforts are all moving forwards. Other NOAA projects focus on a variety of methods to absorb CO2 in the oceans, including fertilizing the water with iron to grow more phytoplankton and farming seaweed.
The programme intentionally took a diverse approach testing various options. “We’re not at a point yet where we can put together our knowledge and say which methods work at scale,” says a former government employee familiar with the effort. They declined to be named because they were fired as part of mass lay-offs by the Trump administration and fear retaliation.",https://www.nature.com/articles/d41586-025-01233-6
Ancient DNA reveals Phoenicians’ surprising genetic ancestry,23 APR 2025,"A death mask from the third or second century BC found in the Phoenician trading city of Carthage in what is now Tunisia.Credit: Peter Horree/Alamy
An ancient Middle Eastern civilization that developed an early alphabet spread its culture far and wide — but not its DNA, finds a 23 April Nature study1 of hundreds of ancient human genomes.
Phoenician civilization emerged more than 3,000 years ago, centred around what is now Lebanon, before expanding across the Mediterranean Sea. Middle Eastern Phoenician city-states eventually fell to other groups, but the culture thrived farther west — most notably in Carthage, in what is now Tunisia, until its destruction in 146 BC.
From Vikings to Beethoven: what your DNA says about your ancient relatives
Phoenician city-states shared languages — recorded with an alphabet that was a precursor to Greek and Latin letters — religious practices and maritime trading economies. Many researchers have presumed that their inhabitants also shared ancestries connected to the culture’s Middle Eastern origins.
To study this history, population geneticist Harald Ringbauer at the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany, and his colleagues analysed the DNA from the remains of around 200 people from Phoenician archaeological sites in the Middle East, Europe and North Africa.
Ancestry puzzle
To Ringbauer’s surprise, people from Mediterranean outposts of Phoenician culture — also known as Punic people — shared no ancestry with ancient Middle Easterners, even those from sites linked to Phoenicians and their forebears the Canaanites.
But neither did Punic people’s genomes always resemble those of people from other local populations, such as those in Sardinia and Ibiza. Instead, Punic people shared an ancestry profile resembling those of ancient inhabitants of Greece and Sicily. Over time, North African ancestry entered the mix — reflecting the rise of Carthage after 500 BC.",https://www.nature.com/articles/d41586-025-01283-w
Inside the quest to digitally unroll ancient scrolls burnt by Vesuvius,23 APR 2025,"A Herculaneum scroll, burnt and encased in volcanic material, on display at the National Library in Naples.Credit: Salvatore Laporta/AP via Alamy
On 27 March, a private jet arrived at London Luton Airport with some unusual, delicate cargo. Rather than designer luggage, the plane carried 18 ancient scrolls from the Vittorio Emanuele III National Library in Naples, Italy. The tightly rolled papyri were being transported to the Diamond Light Source particle accelerator near Oxford, where researchers used the synchrotron’s powerful X-rays to reveal the scrolls’ contents.
How AI is unlocking ancient texts — and could rewrite history
The mission is part of a huge scaling up of efforts to decipher the ‘Herculaneum scrolls’, burnt and buried in the eruption of Mount Vesuvius in AD 79, after text inside one of them was successfully deciphered using artificial intelligence (AI) last year. “It’s like a dream” to have reached this point, says Brent Seales, a computer scientist at the University of Kentucky in Lexington, who has been working to read the scrolls for 20 years. “It seems so impossible and yet we’re doing it.”
A first look at the newest scans reveals that at least five of the scrolls show what look like clear signs of visible ink, researchers tell Nature. That’s “very promising”, says Stephen Parsons, a computer scientist at the University of Kentucky who is also involved with efforts to read the scrolls. It means that the scrolls could be easier to read than previously thought, he adds. Meanwhile, a papyrus at the Bodleian Libraries at the University of Oxford, scanned last year, is yielding unprecedented amounts of data, and dozens more scrolls are due to be scanned in France next month.
Buried treasure
More than 1,800 carbonized papyri were discovered in the eighteenth century among the remains of a luxurious Roman villa at Herculaneum, near Naples. Although many were torn to pieces by various efforts to open them, several hundred intact scrolls remain. They offer an unprecedented cache of ancient knowledge, potentially containing completely unknown texts direct from the pens of their Greek and Roman authors. “Everything we find is a surprise,” says Federica Nicolardi, a papyrologist at the University of Naples Federico II, who accompanied the most recently scanned scrolls on their journey from Italy to Diamond.
A scroll in its 3D-printed protective case is prepared for scanning at the Diamond Light Source particle accelerator.Credit: Emli Bendixen for Nature
The trip was part of the Vesuvius Challenge, a competition that Seales set up in 2023 with Silicon Valley entrepreneur Nat Friedman, to encourage efforts to decipher computed tomography (CT) scans of the unopened Herculaneum scrolls. In February last year, the challenge — for which Parsons is project lead — awarded US$700,000 to a team of students who developed an AI tool that revealed the first paragraphs of a scroll, a Greek philosophical text about music and pleasure possibly written by the philosopher Philodemus.
The focus of the Vesuvius Challenge is now to optimize and automate the techniques, says Seales, and ultimately to scan and read all of the surviving scrolls.
Scaling up
Until now, only five of the scrolls had been imaged at high resolution, so an important first step was to gather more scans. Nicolardi selected the 18 papyri for this phase, prioritizing intact scrolls that might contain complete texts, as well as scrolls with a range of shapes — some are flattened, others compressed along their length like a spring — to test how the machine-learning algorithms cope with different patterns of distortion.
Diamond is one of the few facilities that can produce X-rays to scan these scrolls at sufficiently high resolution. But transporting each fragile piece is challenging. “It’s like papier mâché made out of glass,” says Seales. “If you dropped it, it would probably shatter.” Researchers in Naples modelled the external shapes of the scrolls using photogrammetry, then 3D-printed customized travel cases to snugly fit each one.
The scrolls were scanned inside their protective cases in late March, using an X-ray beam of 53 keV to give a resolution of 8 micrometres. In a control room nearby, the cross-section of the papyrus showed up on the computer screen as a complex spiral, thin as silk, glowing white against a dark background.
A freshly scanned scroll, seen from the control room. The cross section on the right hand side of the screen reveals a complex spiral of rolled-up papyrus. Credit: Emli Bendixen for Nature
Each scroll is scanned in dozens of chunks, and the data are recombined into a single data set. The next step is mapping the surface of the wound-up papyrus across all the CT slices so it can be virtually unrolled into a flat image. Initially, this was done painstakingly by hand, taking months, so a major focus of the Vesuvius Challenge is to automate this process. That has proved difficult, especially where different layers of a scroll are squashed tightly together. An innovation in the past few months has been to use imaging tools, originally developed to trace the connections between neurons, to map the horizontal and vertical fibres in the papyrus. “We’re getting really good at finding the fibres,” says Friedman. “From there, it’s much easier to find the surfaces.” By combining this technique with other improvements, “we’re seeing better and better results every week”.
Invisible ink",https://www.nature.com/articles/d41586-025-01087-y
Century-old genetics mystery of Mendel’s peas finally solved,23 APR 2025,"Gregor Mendel cross-bred some 28,000 garden pea plants (Pisum sativum) and studied traits such as their flower colour to make discoveries about genetic inheritance.Credit: imageBROKER/Alamy
The Augustinian friar Gregor Mendel completed his groundbreaking work on genetic inheritance more than 160 years ago, after carefully studying seven traits in peas, including the shape and colour of their seeds and pods. Yet until now, scientists still hadn’t worked out which genes drive three of those traits in the garden pea (Pisum sativum).
In a paper published on 23 April in Nature1, researchers add a fresh chapter to Mendel’s pivotal story, perhaps in the process launching a new era in the genomic study of peas, which are a popular source of plant-based protein.
Scientists published a reference genome for P. sativum in 20192. That digital sequence — a representation of the plant’s DNA — “was a huge breakthrough”, says Clare Coyne, an adjunct plant geneticist at Washington State University in Pullman. “But I would say [the latest study] is an even larger breakthrough. It’s really just an incredible effort.”
Modern tools meet age-old mystery
Mendel, a citizen scientist, famously performed a series of experiments in the mid-nineteenth century in which he cross-bred some 28,000 pea plants to understand how their traits were inherited by future generations. Although at that stage the concept of genes didn’t exist, Mendel concluded that plants were passing along hereditary ‘factors’ to offspring that determined whether they inherited what turned out to be ‘dominant’ or ‘recessive’ versions of genes known as alleles. Scientists continue to study such Mendelian traits today, and have identified thousands of them in humans. However, many of these traits have yet to be linked to a particular gene — and the same had been true of three of Mendel’s original seven pea traits.
Mendel, a friar, is recognized today as the founder of genetics.Credit: Pictorial Press/Alamy
Noam Chayut, an applied crop geneticist at the John Innes Centre (JIC) in Norwich, UK, and a co-author of the current paper, says he and the other team members were intrigued by the enduring mystery and decided that “sequencing and computational tools had advanced enough to tackle the final three” genes. Using the JIC’s Germplasm Resource Unit — which houses more than 3,500 pea variants, alongside publicly available genomic data sets — the group amassed and deep sequenced nearly 700 pea genomes. These contained roughly 155 million single-nucleotide polymorphisms (SNPs) — single base-pair differences in the DNA sequences compared with the standard, or ‘reference’, P. sativum genome.
Using several methods, including selective breeding of pea plants and genome-wide association studies, which probe each genome for differences in the number and location of SNPs, the group identified the genes linked to the three remaining traits. Specifically, the researchers found that pea-pod colour is controlled by a gene that disrupts chlorophyll biosynthesis, leading to either green or yellow pods. They also identified two genes that probably help to control pod shape by inducing disruption of cell-wall thickening in the plant. And they determined that a deletion in the genetic code at a particular point in another gene can cause changes in the branching or clustering of flowers on the plants — a process known as fasciation.
A long road
Pulling together several methods meant that the work took six years to complete, and Chayut says it was possible only because of the interdisciplinary nature of the team, with each member bringing a necessary skill to the partnership. “The most important and beautiful part of this research is the collaboration,” he says.",https://www.nature.com/articles/d41586-025-01269-8
"‘Dark matter’, 'Big Bang' and ‘spin’: how physics terms can confuse researchers",22 APR 2025,,https://www.nature.com/articles/d41586-025-01089-w
Brand-new colour created by tricking human eyes with laser,18 APR 2025,"Researchers used lasers to stimulate individual cone cells in the retina — leading to the perception of a completely new colour.Credit: George Pachantouris/Getty
Five people have been able to perceive a colour never before seen by human eyes, after researchers used lasers and tracking technology to selectively activate certain cells in their retinas. The blue-greenish hue has an intensity, or ‘saturation’, outside the natural range of colours seen by humans.
The work is “amazing technically” and an “extraordinary achievement”, says Kimberly Jameson, a colour-vision scientist at the University of California, Irvine.
This is not the first time researchers have stimulated individual cone cells — the photoreceptors in the eye whose signals the brain interprets as colour. But this time it was done across an area large enough to alter a person’s vision substantially. “What is novel in this study is the evidence that such new colours can, in fact, be perceived,” says Sérgio Nascimento, a physicist specializing in human vision at the University of Minho in Braga, Portugal.
Off-the-charts intense
The researchers, who published details of the technique in Science Advances on 18 April1, call the otherwise imperceptible colour ‘olo’. It is something like a peacock blue or teal, “but the level of saturation is off-the-charts”, says Ren Ng, a computer scientist and vision researcher at the University of California, Berkeley, who was both a co-author of the study and one of the test participants.
The method — dubbed Oz and run by software called Wizard — works by controlling the precise doses of light delivered to each cell in the retina, to spoof the signals the brain uses to interpret colour or to create signals it has never experienced before.
Ng says the technique has the potential to create other new colours. It could also allow people with colour blindness, for which there are no effective treatments, to perceive differences in hue that they would not otherwise, he says.
That would take a lot of work. So far, the team can carefully control colour in just a small area of vision — roughly twice the diameter that the Moon appears to cover in the sky — and the method requires technology available to very few labs. But, even if it doesn’t end up being applied widely, the research is “an impressive technical accomplishment”, says Jenny Bosten, a visual neuroscientist at the University of Sussex in Brighton, UK. “There is a lot of potential for future research using the technique.”
Fingerprints of light
Human colour vision comes from the brain comparing the signals it receives from three types of light-detecting cone cell. Each one is sensitive to a different but overlapping range of wavelengths. At shorter, bluer wavelengths, the S cone is most responsive, whereas the M, or medium, cone is activated most by greenish light. The L cone is more sensitive than the others to longer-wavelength red light. Every colour that humans can see comes to the brain as a characteristic level of activation of these three cell types, analogous to a fingerprint or set of coordinates.
Because the M cone is in the middle of the spectrum, light activating it always activates neighbouring S or L cones, as well. Ng and his colleagues wondered whether, if the M cone was stimulated by itself, it would create a new colour.
The team first mapped the retinas of each trial participant, marking the position and type of each cell, using a technique developed by co-authors at the University of Washington in Seattle2. This allowed them to track each person’s eye movements and train laser light on individual cone cells.
They then stimulated just the M cones with microdoses of laser light. To test what the participants were seeing, the team asked them to match the colour they perceived with examples of light of a single wavelength. There was no match — the olo colour seemed to be more intense than even the most vibrant blue-green colour possible in normal vision. Participants had to ‘wash out’ the olo colour by adding white light to make it match the closest natural colour, says Ng.",https://www.nature.com/articles/d41586-025-01252-3
"Signs of life on a distant planet? Not so fast, say these astronomers",17 APR 2025,"An artist’s impression of K2-18 b. Researchers report finding a signature of life’s activity in the planet’s atmosphere.Credit: ESA/Hubble, M. Kornmesser
A team of astronomers made worldwide headlines last night with claims that they had found the “strongest hints yet of biological activity outside the Solar System”. The scientists say that a distant planet called K2-18 b has one or more molecules in its atmosphere that might have been generated by living things1.
The announcement has been met with floods of scepticism from other researchers who study such ‘biosignatures’ in exoplanet atmospheres.
“It is not strong evidence,” says Stephen Schmidt, an astronomer at Johns Hopkins University in Baltimore, Maryland. “It’s almost certainly not life,” says Tessa Fisher, an astrobiologist at the University of Arizona in Tucson.
Here, Nature explores the high-profile claim — and why many scientists say it’s far from proof of alien life.
What has been found?
Using the James Webb Space Telescope (JWST), the team, led by scientists at the University of Cambridge, UK, reported finding hints of the molecule dimethyl sulfide (DMS), a pungent compound that can be produced by bacteria, in the atmosphere of K2-18 b, a planet smaller than Neptune that lies about 38 parsecs from Earth. The scientists detected the molecule by analysing starlight as it filtered through the planet’s atmosphere; different chemicals leave identifying imprints in the light’s spectrum. The data also suggest that the related molecule dimethyl disulfide (DMDS) might be present, either in addition to or instead of DMS1. These chemicals are intriguing because, on Earth, they are produced by living organisms such as marine phytoplankton.
In 2023, the researchers reported similar findings2. In the follow-up work, the scientists conducted a search using a different set of wavelengths and found a stronger and cleaner signal that the molecules are present, they say.
Teasing out the detailed chemistry of a faraway planet is a technical tour de force, the team says. “What we are seeing is a major paradigm shift in the field of exoplanet science,” said team leader Nikku Madhusudhan, an astronomer at the University of Cambridge, in a livestreamed colloquium on 17 April. He did not respond to a request for an interview before this article was published.
Why is it important?
Scientists have been looking for life beyond Earth for centuries. If DMS and DMDS do exist in the planet’s atmosphere, and if they were formed by biological activity, the findings would be groundbreaking.
The work also marks a step towards understanding planets similar to K2-18 b, which are some of the most common of the more than 5,800 planets that have so far been identified throughout the Universe. They are referred to as mini-Neptunes on the basis of their mass, beyond which little is known about their make-up. Some researchers, including Madhusudhan’s team, say that some could be exotic water worlds cloaked in hydrogen atmospheres3. If so, they could be some of the best places to look for extraterrestrial life.
Why are other researchers sceptical?
For starters, there are questions about whether K2-18 b even has water — or a surface that could support life. Modelling studies of it and similar planets suggest that they are probably barren4,5. “A lifeless mini-Neptune scenario remains the most parsimonious explanation,” says Joshua Krissansen-Totton, a planetary scientist at the University of Washington in Seattle.
Then there’s the issue of whether DMS or DMDS is actually present, or whether the signal is spurious. The measurement reported by the Cambridge team is “really pushing the limit of what JWST can do”, says Laura Kreidberg, an astronomer at the Max Planck Institute for Astronomy in Heidelberg, Germany.
Schmidt and his colleagues this year re-analysed the 2023 claim from the Cambridge team and found no evidence of biosignature molecules in the data6. Schmidt says that the new observations are “pretty noisy, and any reported features could still just be statistical fluctuations”. The Cambridge researchers, however, say that there is just a 0.3% probability that the signal is due to chance.",https://www.nature.com/articles/d41586-025-01264-z
Exclusive: Trump team freezes new NSF awards — and could soon axe hundreds of grants,17 APR 2025,"Update: On the afternoon of 18 April, the NSF announced it would begin terminating active research grants. These grants contain language related to diversity, equity and inclusion (DEI) and had been flagged in an initial review ordered by the Trump administration. In an update to agency priorities, NSF director Sethuraman Panchanathan wrote that efforts to broaden participation in research “should not preference some groups at the expense of others”.
All new research grants have been frozen at the US National Science Foundation (NSF) — an action apparently ordered by the Department of Government Efficiency (DOGE), an initiative by billionaire entrepreneur Elon Musk to cut spending and workers across the US government.
DOGE is also reviewing a list of active research grants, assessed in February by the NSF, for terms associated with DEI. It is considering terminating more than 200 of them, NSF staff members have told Nature.
NSF slashes prestigious PhD fellowship awards by half
On Monday, three DOGE members arrived at the NSF headquarters in Alexandria, Virginia. NSF employees say that DOGE has directed hundreds of research proposals — previously approved through a multi-step review process, but not yet finalized — to be sent back to NSF programme officers, who have been told to perform unspecified “mitigation work”. Science first reported the arrival of DOGE at the NSF this week.
With a budget of US$9 billion, the NSF is one of the largest funders of basic research in the world. From the start of Donald Trump’s second US presidency, the agency has gone through whiplash-inducing changes: it froze all grant payments and then unfroze them in February following court orders; it fired its probationary employees in February and weeks later rehired half of them. And earlier this month, the agency halved its graduate research fellowship programme, offering only 1,000 positions instead of the usual 2,000.
The NSF has been under heightened scrutiny by Ted Cruz, a Republican senator from Texas who now chairs the US Senate Committee on Commerce, Science, and Transportation. In October 2024, Cruz released a report alleging that 3,483 grants awarded between January 2021 and April 2024 by the NSF during the administration of Trump’s predecessor, Joe Biden, “went to questionable projects that promoted diversity, equity, and inclusion (DEI) tenets”, amounting to $2 billion. Today, Democrats in the US House of Representatives Committee on Science, Space, and Technology released an analysis of the report. The analysis claims that the report has major flaws, suggesting that it “jeopardizes the economic and national security of the United States” by “undermining the important work of scientific researchers, educators, and institutions”.
A spokesperson for the NSF says it “continues to issue awards” and declined to answer Nature’s questions. Kush Desai, a spokesperson for the White House, says that “the Trump administration is committed to ensuring that federal research spending is in line with the priorities of everyday Americans”. Cruz’s office did not respond to Nature’s requests for comment by the time this article was published.
To better understand the situation at the NSF, Nature spoke to five staff members, who were granted anonymity because they are not authorized to speak to the press.
DOGE arrives
As DOGE visited other US agencies over the past two months — in some cases dismantling them entirely — NSF staffers held their collective breath.
‘Totally broken’: how Trump 2.0 has paralysed work at US science agencies
But on Wednesday, DOGE turned its attention to the NSF’s grants, the focus of the agency’s mission. Documents seen by Nature show that two members of DOGE, Luke Farritor and Zachary Terrell, have accessed grant-management systems to prevent funding for approved grants that were awaiting finalization. “That, of course, raises the hairs on the back of our neck in a worrisome way,” an NSF programme officer says.
Research projects at the NSF go through several steps before approval. Proposals are first submitted to NSF programme officers with expertise in the relevant scientific field. If the proposals pass muster, the officers then commission a review from independent specialists outside the agency. Only the strongest applications pass this step — the typical success rate is between 20% and 30%. Division directors at the NSF then give the ultimate approval, and grants are finalized by the Division of Grants and Agreements. This is where grants are currently being sent back from.
Proposals that receive final approval are essentially always funded — until now, the employees say. Before DOGE’s arrival, new research awards at the agency had slowed by half relative to last year, Science has reported. On 16 April, they stopped completely.",https://www.nature.com/articles/d41586-025-01263-0
‘Totally broken’: how Trump 2.0 has paralysed work at US science agencies,17 APR 2025,"During the week of 1 April, workers at the US Department of Health and Human Services waited in line to access their offices as mass lay-offs began.Credit: Kevin Lamarque/Reuters
As the administration of President Donald Trump continues its campaign to reshape the US government with spending cuts and mass lay-offs, some scientists still employed at government agencies say that their work has become impossible.
The US National Institutes of Health (NIH), a massive biomedical-research funder that also employs thousands of scientists at its own laboratories, is “totally broken and non-functional right now”, according to a principal investigator at the NIH who asked for anonymity because they are not authorized to speak to the press. “We can’t hire people. We can’t recruit people. We can’t talk to people on the outside. We cannot travel,” they say.
How Trump is following Project 2025’s radical roadmap to defund science
Other government scientists, who Nature granted anonymity for similar reasons, say that they can’t afford publication fees or the supplies they need to process lab samples.
At the US National Oceanic and Atmospheric Administration (NOAA) — which monitors Earth’s oceans and atmosphere and provides weather forecasting services — some scientists cannot do fieldwork because many of the contractors they have historically worked with have been furloughed.
Meanwhile, the US Department of Government Efficiency, effectively run by billionaire Elon Musk — a Trump adviser — has been sowing fear among federal workers with its visits to various agencies, threatening possible workforce cuts and more.
Federal science policy “wasn’t perfect”, and some reforms would have been welcomed before Trump took office, the NIH principal investigator says. But now the administration is “tearing everything down … in a way that seems motivated to enrich the people who are doing it, rather than actually making the government work better”, they say.
The White House did not respond to a request for comment. NOAA and the Department of Health and Human Services (HHS), which oversees the NIH, also did not respond.
Short on supplies
In February, the Trump administration began to put a spending limit of US$1.00 on nearly all government credit cards. The effect has been disastrous at science agencies, researchers say. NIH labs haven’t been able to purchase essential items: gloves, pipettes, paper towels, Petri dishes, reagents, fluorescent dyes and storage vials. One lab has run out of a chemical needed to freeze brains from organ donors for storage and processing. The news website STAT reported last week that some purchasing restrictions will be lifted at the NIH, but the HHS did not respond to Nature’s request to confirm the change.
Clinical trials run by the NIH have been affected, too. One agency lab that analyses blood samples for more than 200 trials — studying cancer treatments, organ transplants and more — lost half of its staff during lay-offs. On busy days, the lab’s workers cannot process samples quickly enough and must borrow colleagues from other groups to help, a lab member says.
Demonstrators protested over the firing of probationary workers at the US National Oceanic and Atmospheric Administration in Silver Spring, Maryland, in March.Credit: Chip Somodevilla/Getty
The researcher was fired in February as part of an initial sweep of probationary workers — those who have usually been in their positions for less than two years — following directives from the US Office of Personnel and Management (OPM). When a federal judge blocked the firings later that month, saying that the OPM did “not have any authority whatsoever” to do so, probationary staff members were ‘reinstated’, but instead of being allowed to return, some were placed on administrative leave. “I want nothing more than to just be able to go back and do my job,” the researcher says. Although they are happy to be paid again, “I feel kind of helpless sitting here,” they say. “It does feel like, ‘Oh, this is ironic’, that this is actually a waste of taxpayer money”, given the cuts have been justified on the grounds of government efficiency, they add.
The US Supreme Court halted the order to reinstate probationary workers on 8 April. It’s unclear what will happen to the NIH researcher, but NOAA moved last week to fire its reinstated probationary workers — this time, presumably, for good.
Some NOAA workers had already decided that they couldn’t just sit around. Fearing that they would be laid off, one probationary scientist who was fired and then rehired, only to be placed on administrative leave, downloaded work files to their personal computer in late February. They spent several weeks analysing data with former colleagues while awaiting word regarding their employment status. “I’m just doing my research,” the scientist told Nature before they were fired the second time. Their response when asked whether it was legal to work while on administrative leave: “I’m not entirely sure. I’m not a lawyer.”
Off-mission work
Some federal scientists say that the government seems to be deliberately trying to make their work harder. “We are constantly barraged with enormous amounts of, let me be frank, bullshit administrative work,” says an NIH researcher. They say that Trump team officials send requests — such as gathering a list of all contract employees — alongside ultimatums that suggest employees will be fired if they fail to respond within 24 hours. The stream of demands is “strangling many aspects of the function of NIH with red tape”, they say.",https://www.nature.com/articles/d41586-025-01245-2
Invasion of the ‘journal snatchers’: the firms that buy science publications and turn them rogue,17 APR 2025,"Publishers are being offered hundreds of thousands of euros for journals indexed by scholarly databases.Credit: Dave Whitney/Getty
Research-integrity analysts are warning that ‘journal snatchers’ — companies that acquire scholarly journals from reputable publishers — are turning legitimate titles into predatory, low-quality publications with questionable practices.
In an analysis published on the preprint repository Zenodo in January1, researchers identified three dozen journals that have been caught in this predicament after being bought by what they describe as a network of recently established international companies with no track record in the publishing industry. The scholarly database Scopus has removed the titles from its index after an investigation.
“We found at least 36 journals but we think that there may be more,” says study co-author Alberto Martín-Martín, an information scientist at the University of Granada in Spain. Nature was able to reach one of the companies named in the study, Oxbridge Publishing House, which disputes the allegations.
Recent takeover
The titles were previously indexed by databases such as Scopus and Web of Science, and were owned by various institutions, including the Dutch publishing giant Elsevier; the academic publisher Palgrave Macmillan, based in London; Indiana University Northwest, in Gary, Indiana; and the University of São Paulo, in Brazil. They range in discipline from linguistics, psychology and criminology to biology and medicine. (Palgrave Macmillan is owned by Springer Nature, which also publishes Nature. Nature’s news team is independent of its publisher.)
Predatory publishers’ latest scam: bootlegged and rebranded papers
Martín-Martín’s study describes how, in the past few years, these journals were acquired by various companies, including Oxbridge Publishing House — a firm registered in the United Kingdom in September 2022 — another UK-based firm called Open Access Text, JCF Corp in Singapore and Intellectual Edge Consultancy in Malaysia.
According to e-mails evaluated by Martín-Martín and his co-author, Emilio Delgado López-Cózar, also an information scientist at Granada, publishers are being offered hundreds of thousands of euros in exchange for each journal. “For small journals, this is a very attractive offer,” Martín-Martín says.
After acquisition, the analysis found, a common trend appears across the publications: the journals introduce or raise article-processing charges — fees some open-access journals impose for publishing papers — and churn out more studies. Many of these papers are outside the scope of topics covered by the journal before acquisition.
These practices are typically associated with predatory publishing, where questionable publishers cut corners to generate low-quality or fraudulent research papers in exchange for high publication fees.
Ownership question
Most of the companies named in the analysis did not respond to Nature’s requests for comment. David Radhor, relationship manager at Oxbridge Publishing House, says the company is “not a publisher” and does not directly own all of the titles in Martín-Martín’s preprint. (The study claims that Oxbridge has directors in common with some of the other companies, and suggests that it is part of a network of linked firms that are actively acquiring journals.)
Radhor adds that for the journals Oxbridge Publishing House does own, the company “has not been involved in their editorial decision-making” and does not have oversight of the number of papers published, the article-processing charges or the authors who submit manuscripts. Those decisions are made independently by each journal’s editorial board, he says. “Our role is primarily operational, focusing on production and formatting, publishing and distribution, sales and revenue management, marketing and promotion, legal and compliance, and technology and infrastructure.”
How big is science’s fake-paper problem?
Nature also attempted to contact all 36 journals listed in the study. Amjid Iqbal, managing editor of the American Journal of Health Behavior (AJHB) in Los Angeles, California, says his journal increased their publication fees (from US$1,595 to £2,000 according to the study) because of inflation and because its vendors increased their charges. He adds that all editorial decisions are made by the journal’s editorial board. The study claims that payments to AJHB from authors based in the United States, Europe, and the Middle East are handled by Oxbridge Publishing House, but Iqbal says that the journal has no relationship with the company.
Representatives from the International Journal of Medicine and Science of Physical Activity and Sport and ArtsEduca declined to answer questions about their ownership and editorial oversight. The remaining journals did not respond to requests for comment.
In two other cases, researchers contacted by Nature said they had been falsely listed as editors on journal websites.
“One of the problems of these companies is that when they buy journals, they are not very open about this, and in many cases, the journals don’t give any information about this new owner,” Martín-Martín says. “They don’t even display the name of the new owner on the journal website.”",https://www.nature.com/articles/d41586-025-01198-6
25 million deaths: what could happen if the US ends global health funding,17 APR 2025,"Scientists are trying to measure the impact on global health of funding cuts by the US administration. Credit: Luis Tato/AFP via Getty
The United States spent roughly US$12 billion on global health in 2024. Without that yearly spending, roughly 25 million people could die in the next 15 years, according to models that have estimated the impact of such cuts on programmes for tuberculosis, HIV, family planning and maternal and child health.
The United States has long been the largest donor for health initiatives in poor countries, accounting for almost one-quarter of all global health assistance from donors. These investments have contributed to consistent public-health gains for more than a decade. HIV deaths, for example, dropped by 51% globally between 2010 and 2023, and deaths owing to tuberculosis dropped by 23% between 2015 and 2023.
But the administration of US President Donald Trump has cut billions of dollars of spending for global health, including dismantling the US Agency for International Development (USAID) and freezing foreign-aid contributions — some of which has been temporarily restored.
Researchers have been trying to study the potential impact of the funding cuts. John Stover, an infectious-diseases modeller at Avenir Health, a global-health organization in Glastonbury, Connecticut, and his colleagues used mathematical models to estimate health outcomes, should all US funding for global health be cut and not replaced, compared with outcomes if funding provided in 2024 were to continue through to 2040. The results were posted on the preprint server SSRN earlier this month and have not been peer reviewed1.
Source: Stover/Preprints with The Lancet
The researchers “use a combination of robust, well-established and proven mathematical models and analytical approaches to estimate the impact”, says Andrew Vallely, a clinical epidemiologist at the Kirby Institute at the University of New South Wales in Sydney, Australia. “Their findings are devastating to read” and “a wake-up call for all of us working in global health.”
James Trauer, an infectious-disease modeller at Monash University in Melbourne, Australia, adds: “These models are probably as good as we have available at the moment for predicting the direct effects of the funding cuts on these various programmes.”
On 28 March, Marco Rubio, the US secretary of state, said that the government was reorienting its foreign-assistance programmes to align with the country’s priorities. “We are continuing essential life-saving programmes and making strategic investments that strengthen our partners and our own country.”
HIV and AIDS
The researchers modelled the impact of cutting the US President’s Emergency Plan for AIDS Relief (PEPFAR) in the 55 countries it supports, including stopping the delivery of treatments, tests and interventions that prevent transmission. The programme has been affected by funding freezes.
Without PEPFAR, there would be 15 million more deaths from AIDS by 2040 than if the programme continued (see ‘A world without US aid’). More than 60% of those deaths would take place in six African countries, including Mozambique, Nigeria and Uganda. Roughly 14 million extra children would become orphans as a result of those AIDS deaths — a trend that had been expected to decrease over the next 15 years. And 26 million more people could become infected with HIV without PEPFAR.
Source: Stover/Preprints with The Lancet
The impact varies considerably depending on how reliant a country is on US government support, says Stover. In Uganda, for example, 65% of funding for HIV research comes from the United States, he says. Some models estimated the effects of a partial-funding scenario; in this case, continuing funding for treatment alone could avert 97% of the extra deaths and 90% of the extra new HIV infections.
Tuberculosis
The global number of infections of Mycobacterium tuberculosis — the bacterium that causes the world’s deadliest infectious disease — is also expected to ramp up without US aid funding. Researchers looked at the impact of cuts to USAID and US contributions to the Global Fund to Fight AIDS, Tuberculosis and Malaria across 79 low- and middle-income countries — although it is not yet clear by how much US contributions to the fund will shrink in the coming years. These would contribute to 69 million more M. tuberculosis infections and 2 million more deaths by 2040.
These estimates are broadly consistent with other efforts to assess the impact, says Trauer.
“There’s been tremendous progress made in global health over the last couple of decades and we’re at risk of losing a lot of that,” says Katherine Horton, an epidemiologist at the London School of Hygiene & Tropical Medicine, who contributed to the modelling on tuberculosis.",https://www.nature.com/articles/d41586-025-01191-z
What a trove of potato genomes reveals about the humble spud,16 APR 2025,,https://www.nature.com/articles/d41586-025-01247-0
Japan’s big bet on stem-cell therapies might soon pay off with medical breakthroughs,16 APR 2025,"Japan is brimming with signs of an approaching medical revolution. Shiny white robots are tending dishes of cells, rows of incubators hum in new facilities, and a deluxe, plush-carpeted hospital is getting ready to welcome its first patients.
Building on the Nobel-prizewinning work of stem-cell scientist Shinya Yamanaka, researchers across the country are crafting cells into strips of retina, sheets of cardiac muscle or blobs of neurons, in the hope of treating blindness, mending hearts and reversing neurodegeneration. Results from early-stage clinical trials — some announced just in the past few weeks — suggest that the cells might actually be working to treat conditions as varied as Parkinson’s disease and spinal-cord injury.
‘Big leap’ for Parkinson’s treatment: symptoms improve in stem-cells trials
Now, after nearly two decades of hard work and setbacks, many say that Japan is on the cusp of bringing these therapies to market.
Yamanaka, who runs a lab at Kyoto University, discovered in 2006 that adult cells could be reprogrammed into an embryonic-like state, capable of becoming practically any kind of tissue1. These induced pluripotent stem cells — or iPS cells — won Yamanaka the Nobel Prize in Physiology or Medicine in 2012, and propelled him to superstar status. They have become a symbol of the country’s global scientific aspirations.
The Japanese government has poured more than ¥110 billion (US$760 million today) into research and development on regenerative medicine, on top of billions more from private funders, organizations and companies. “People thought, ‘Now we can treat any incurable disease’,” says Shigeto Shimmura, director of Fujita Health University Haneda Clinic. “There was so much hype.”
Scientists launched clinical trials and start-up firms. Large biotech companies swooped in, investing even more in manufacturing hubs. Now, medical facilities are preparing to welcome a rush of patients from Japan and abroad. “Regenerative medicine in Japan is moving very dramatically,” says Masayo Takahashi, an ophthalmologist at Kobe City Eye Hospital and president of the biotechnology company, Vision Care. In 2014, she became the first to treat someone with cells derived from iPS cells.
Masayo Takahashi ran the first clinical trials for iPS cells.Credit: Ben Weller for Nature
There are more than 60 iPS-cell clinical trials in progress worldwide, nearly one-third of them in Japan. The treatments have proved to be safe and shown signs of benefit. Moreover, the technology has been improving apace, says Shimmura. And thanks to a fast-track approvals process for regenerative medicine, Japan could become the first country to approve iPS-cell-based treatments. This could happen within a year for Parkinson’s disease.
But those approvals are not yet in hand, treatment costs are high, large trials showing clear clinical benefit have yet to materialize, and concerns about safety could still sap the public’s willingness to try this treatment. “We’re down to realizing what the potential of these cells are, and what the limits are,” Shimmura says.
Eye see
Yamanaka’s iPS cells promised to bypass a bioethical stand-off that had threatened the potential of embryonic stem cells for a decade. Because production of iPS cells doesn’t require the destruction of human embryos, they were considered ethically less fraught. Furthermore, because they could be made from the cells of the person in need of treatment, they promised to offer transplantable tissues without the need for immune-suppressing drugs.
In 2014, Takahashi put this idea to the test. She took skin cells from a 70-year-old woman with a progressive eye condition known as macular degeneration and guided them into a younger, more pliable state using a recipe similar to the one Yamanaka had devised and refined. The resulting iPS cells were then grown into thin sheets of retinal cells and transplanted into the woman’s eye, where they have survived for ten years and prevented further vision loss, Takahashi says.
It was a procedure with practical limitations, however. Self-derived, or ‘autologous’, cell therapies are time-consuming and expensive to make, and the large cell-sheets that researchers crafted for implantation required intrusive surgery. Takahashi says she chose this approach to ensure the highest chance of clinical benefit — to demonstrate to the world what was possible. It was designed to be “scientifically, the best treatment”.
A technician at Vision Care in Kobe makes capillary tubes for injecting cells into the eye.Credit: Ben Weller for Nature
But Takahashi wanted to create a commercially viable treatment. This meant a change in approach, using cells from donors that could be mass-produced, and finding less invasive ways of getting them into the eye.
She and her team initially tried injecting a pool of donor-derived cells just under the retina, where they might form sheets on their own. But the researchers had limited control over where the cells grew. They next tried growing strips of cells, 2 centimetres long and 200 micrometres thick. They used a tube to slide several of these strips onto the retina through a tiny incision in the eye, in the hope that they would expand into sheets.
Don’t rush promising stem-cell therapies
Results published in March suggest that for three individuals who received the treatment, the cells have survived and are safe one year after surgery2. But the signs of benefit are mixed. One of the three individuals said she could see her husband’s face clearly for the first time in ten years, but only through a small section of her eye, where the cells had been transplanted.
The difficulties might come down to the retina’s natural resistance to regeneration. But other parts of the eye might benefit more from cell therapies: the cornea, the clear covering that lets light in, is maintained by a pool of stem cells and constantly being rebuilt.
In November, Kohji Nishida, an ophthalmologist at Osaka University, and his colleagues published the results of donor iPS-cell-derived transplants into four individuals for whom those natural cornea-building stem cells had been depleted — a condition that results in corneal scarring and vision impairment. Three of them saw sustained gains in vision3.
Nishida has since set up a start-up company, Raymei, which plans to launch a larger trial and aims to gain formal approval in three years. “The next clinical trial is pivotal,” he says.
Brain and back
The regeneration of nerve tissue has been one of the great hopes for iPS cells, but it has been fraught with challenges. Jun Takahashi, husband to Masayo, has an office lined with statues of elephants and an imposing, life-sized set of navy-blue samurai armour, “just to encourage my lab”, he says.
Takahashi is a neurosurgeon and the director of Kyoto University’s Center for iPS Cell Research and Application (CiRA), an institute established by Yamanaka as a hub for iPS-cell research.
Jun Takahashi is trying to treat Parkinson’s.Credit: Ben Weller for Nature
In 2018, Takahashi led a trial that used donor-derived iPS cells to treat Parkinson’s disease, a degenerative brain condition that affects movement. The team injected between five million and ten million cells, which had been coaxed into acting like neural progenitors, into the right and left brain hemispheres of seven individuals with the disorder.
Two years after the treatment, according to results published this week, at least four individuals saw noticeable improvements in symptoms, such as fewer tremors and rigid movements4. One went from requiring assistance to being able to live independently when not taking their regular medications. Another trial involving 12 individuals using neural progenitors derived from embryonic stem cells also showed, on average, moderate improvements in movement 18 months after the transplant5. Knowing that the treatment could work has brought Takahashi great relief.
Paralysed man stands again after receiving ‘reprogrammed’ stem cells
But, unlike his wife, he has not set up a company to develop the technology for manufacturing the cells and conducting the surgery. Instead, he has instead transferred that knowledge to Sumitomo Pharma, based in Osaka. “As a scientist, I am kind of satisfied,” he says. He has now diverted his attention to developing cell therapies for treating stroke.
Hideyuki Okano, a stem-cell scientist at Keio University in Tokyo, has demonstrated another potential trick for iPS cells. Between 2019 and 2023, he and his colleagues used donor-derived cells to treat four people with spinal-cord injury. The researchers presented preliminary results — not yet peer reviewed — at a press conference in March, showing that one individual with paralysis can now stand independently and is learning to walk. Another can move some of their arm and leg muscles but cannot stand. Two others did not show substantial improvements.
Similar trials are under way outside Japan, some of which involve many more participants than the Japanese trials. But unlike other regions, Japan has made the path to approval relatively easy, says Clive Svendsen, a stem-cell researcher at Cedars-Sinai Medical Center in Los Angeles, California. In 2013, Japan introduced a system through which regenerative-medicine products could be conditionally approved if they are shown to have no major safety issues and are likely to be efficacious.
Jun Takahashi and a colleague examine a cluster of nerve tissue created from iPS cells (shown magnified on the right).Credit: Ben Weller for Nature
Companies can offer the treatments, with costs mostly covered by the national health system. But they must continue to collect data on safety and efficacy to earn full clinical approval.
Some researchers have raised concerns about this fast-track process and related programmes in Japan. Last year, two of the four products that had received conditional approval under this mechanism — one involving thigh-muscle cell transplants for the heart, the other a gene therapy to treat ulcers in narrowed arteries in the limbs — were withdrawn. The first was rejected for formal approval after nearly a decade on the market because it failed to show clinical benefit. The second was withdrawn about five years after being conditionally approved, because surveillance data did not reproduce results observed in earlier trials.
Hiroshi Kawaguchi, an orthopaedic surgeon at Nadogaya Hospital in Kashiwa, says he is concerned that the fast-track process shifts the cost burden from pharmaceutical companies, which would otherwise have to conduct large-scale trials, to the public insurers, which then pay for expensive, unproven treatments. Last year, Japan’s Ministry of Health, Labour and Welfare issued guidance documents that clarified that conditional approval should not be the ultimate goal for companies.
Others are less concerned about Japan’s fast-track process for conditions that are rare or have few other treatment options. “In order to move this field forward quickly, you’re going to have to have an element of risk,” says Svendsen. “What I’ve seen in Japan has been pretty sensible; they are putting regulations in place.”
iPS cells for all
Even without approvals in hand, the industry is building capacity in the expectation that demand for these treatments will be high. In 2018, Sumitomo Pharma completed construction of what it describes as the world’s first manufacturing facility for donor-derived iPS-cell products. The building, in Osaka, looks like a giant, floating silver box. In 2020, it delivered its first cells for transplant — for the fourth participant in Takahashi’s Parkinson’s trial. The company is also supporting two early-stage Parkinson’s trials in the United States.
Masayo Takahashi has chosen a more portable manufacturing model for her macular-degeneration treatments: a white, muscular-looking, two-armed robot. Powered by machine learning, it checks in on cells’ progress as they are prepared for transplant through a microscope. In 4 months, it can produce enough cells for more than 800 individual treatments.
This robot in Kobe is preparing cells for transplant to treat people with macular degeneration.Credit: Ben Weller for Nature",https://www.nature.com/articles/d41586-025-01143-7
First global pandemic treaty agreed — without the US,16 APR 2025,"A health worker in Zimbabwe receives a COVID-19 vaccination. Many countries struggled to secure vaccine supplies during the pandemic.Credit: Tafadzwa Ufumeli/Getty
For the first time — and despite fears that it might never happen — nations have agreed a series of measures to prevent, prepare for and respond to pandemics. The terms of the first global pandemic accord were still being hashed out at the World Health Organization (WHO) headquarters in Geneva, Switzerland, up until the early hours of 16 April.
“This is a definitive moment in the history of global health,” says Lawrence Gostin, a specialist in health law and policy at Georgetown University in Washington DC, who followed the negotiations closely. The accord “sets out some very important norms to keep the world safe”, he says.
What the WHO’s new treaty could mean for the next pandemic
The accord was agreed without the United States, which withdrew from the pandemic treaty the day that US President Donald Trump was inaugurated in January. This reduces its power, says Gostin, but is also a source of strength. “Instead of collapsing in the face of President Trump’s assault on global health, the world came together.”
The treaty is not perfect, but it represents a major achievement, says Michelle Childs, policy-advocacy director at the Drugs for Neglected Diseases initiative, a non-profit organization in Geneva. “People didn’t think that they’d get to this stage of agreeing at all.”
“I even have goosebumps because I can’t believe we finally finished,” says Precious Matsoso, co-chair of the WHO intergovernmental negotiating body created to draft the treaty in 2021. “It’s been a long journey.”
Pathogen sharing
The treaty lays out the broad outline of a ‘pathogen access and benefit sharing’ system, which grants pharmaceutical companies access to scientific data, such as pathogen samples and genomic sequences, in return for more-equitable sharing of drugs, vaccines and diagnostics during a pandemic.
During the COVID-19 pandemic, vaccines were distributed much slower in low-income countries than in high-income ones, and some countries were accused of hoarding vaccines.
A sticking point for the treaty — which has taken more than three years to negotiate — was reassuring poor countries “that the inequities that we saw in COVID will be addressed”, says Childs. Countries with strong pharmaceutical industries, meanwhile, were concerned about agreeing to share their technology. “It started with some member states saying ‘no’,” says Matsoso. “But eventually, over time, I think there was what I would call the voice of reason.”
Negotiating a pandemic treaty is just the first step — how will countries comply?
The details of how exactly the system will work have yet to be hashed out. But the accord states that there must be provisions for the “rapid and timely” sharing of information, and that manufacturers participating in the agreement must make at least 20% of the vaccines, drugs and diagnostics that they produce available to the WHO during a pandemic.
A spokesperson for the Geneva-based International Federation of Pharmaceutical Manufacturers and Associations says that it’s important that the agreement is translated into a “practical plan” that incentivizes pharmaceutical companies of all sizes to invest in research on pathogens. “Innovation is not guaranteed. It requires the right environment to thrive.”
The draft agreement will be presented at the World Health Assembly in May and will need to be ratified by member states if adopted — a process that could take months or years.
Technology exchange
As well as promoting equitable access to health products, the treaty states that countries should “promote and otherwise facilitate or incentivize” the exchange of technology and know-how to enable manufacturers in low-income nations to produce their own drugs and vaccines. “That should help poorer regions like Africa to become more self-sufficient in the face of a pandemic,” says Gostin.",https://www.nature.com/articles/d41586-025-00839-0
‘Big leap’ for Parkinson’s treatment: symptoms improve in stem-cell trials,16 APR 2025,"Millions of stem cells were injected into the brains of people with Parkinson’s disease, as part of a safety trial.Credit: GJLP/Science Photo Library
Two hotly anticipated clinical trials using stem cells to treat people with Parkinson’s disease have published encouraging results. The early-stage trials demonstrate that injecting stem-cell-derived neurons into the brain is safe1,2. They also show hints of benefit: the transplanted cells can replace the dopamine-producing cells that die off in people with the disease, and survive long enough to produce the crucial hormone. Some participants experienced visible reductions in tremors.
The studies, published by two groups in Nature today, are “a big leap in the field”, says Malin Parmar, a stem-cell biologist at Lund University, Sweden. “These cell products are safe and show signs of cell survival.”
Japan’s big bet on stem-cell therapies might soon pay off with breakthrough therapies
The trials were mainly designed to test safety and were small, involving 19 individuals in total, which is not enough to indicate whether the intervention is effective, says Parmar.
“Some people got slightly better and others didn’t get worse,” says Jeanne Loring, a stem-cell researcher at Scripps Research in La Jolla, California. This could be due to the relatively small number of cells transplanted in these first early-stage trials.
Parkinson’s is a progressive neurological condition driven by the loss of dopamine-producing neurons, which causes tremors, stiffness and slowness in movement. There is currently no cure for the condition, which is projected to affect 25 million people globally by 2050.
Cell therapies are designed to replace damaged neurons, but previous trials using fetal tissue transplants have had mixed results. The latest findings are the first among a handful of global trials testing more-advanced cell therapies.
Cell shots
The larger of the two trials took place in the United States and Canada, involving 9 men and 3 women with Parkinson’s disease, with a median age of 671. The researchers coaxed stem cells from donated human embryos into neural progenitor cells and froze them for safekeeping.
Just before surgery, the cells were thawed and injected into a walnut-shaped, deep-brain structure called the putamen, which is an important motor-relay station. Neurons that die in Parkinson’s disease extend their tentacles out to the putamen.
The stem cells were injected to 18 sites across the putamen in both hemispheres — “to roughly fill up that region of the brain”, says Viviane Tabar, a neurosurgeon at the Memorial Sloan Kettering Cancer Center in New York City who conducted the US surgeries.
Five individuals received a dose of 0.9 million cells and 7 received 2.7 million cells, in the hope that 100,000 and 300,000 cells, respectively, would survive the surgery. A healthy brain typically has 300,000 dopamine-producing neurons. The recipients were given immune-suppressing drugs for one year after the surgery to prevent their bodies from rejecting the transplant.
Brain scans showed an overall increase in dopamine production, suggesting that some neurons survived the entire 18-month observation period, even after the participants stopped receiving immune-suppressing drugs.
On average, individuals who received the low dose showed a 9-point improvement in their symptoms on a standardized assessment for Parkinson’s disease, and those who received the high dose gained 23 points. The assessment measures individuals’ daily life activities, pain levels, sleep and eating. Agnete Kirkeby, a stem-cell scientist at the University of Copenhagen who is involved in a European trial, points out that this metric is subjective and can be influenced by the placebo effect, but says the results warrant larger trials.
Fewer tremors
The second study2, conducted in Japan, started with adult cells from a donor and reverted them to a pluripotent state, from which they could be coaxed into becoming neural progenitor cells. Freshly differentiated cells were immediately injected into participants, comprising four men and three women aged 50–69.
Three individuals received up to 5 million cells and 4 received up to 11 million cells, of which 150,000 and 300,000 cells, respectively, were expected to survive. “This low survival rate is a big problem that needs to be solved,” says Jun Takahashi, a neurosurgeon at Kyoto University in Japan, who led the trial. Participants were given immune-suppressing drugs for 15 months.",https://www.nature.com/articles/d41586-025-01208-7
"Winner, winner, lab-made dinner! Team grows nugget-sized chicken chunk",16 APR 2025,"Researchers grew a single chunk of chicken in the laboratory that was about 7 centimetres long and 2 centimetres thick.Credit: Shoji Takeuchi, The University of Tokyo
Researchers have created what they think is the largest chunk of meat grown in the laboratory yet, thanks to a designer ‘circulatory system’ that delivers nutrients and oxygen into the growing tissue.
Shoji Takeuchi, a biohybrid system engineer at the University of Tokyo, and colleagues report growing a single piece of chicken that measures 7 centimetres long, 4 centimetres wide and 2.25 centimetres thick. Weighing in at 11 grams, it is about the size of a chicken nugget. The work was reported today in Trends in Biotechnology1.
The meat hasn’t yet been made with food-grade materials, so it isn’t ready for consumers’ plates and the team hasn’t tasted it. But the researchers are talking to several companies about developing the technology further.
Mark Post, chief science officer for the company Mosa Meat in Maastricht, the Netherlands, who unveiled the world’s first lab-grown hamburger in 2013, says the work is “an extraordinary engineering achievement”.
Mix and mash
Plenty of people have grown meat in the lab before, using biopsied cells from animals to produce food without slaughter. A handful of companies are now licensed to sell cultivated meat in a few nations, including the United States. Last year, the United Kingdom became the first European country to approve the sale of cultivated meat in pet food.
Lab-grown meat: the science of turning cells into steaks and nuggets
But most of these efforts grow only tiny pieces of meat that are then assembled into a larger product, by printing cells onto an edible scaffold, for example, or by gluing lab-grown bits of meat together with an edible binder. GOOD Meat, a division of the food-technology firm Eat Just in Alameda, California, is licensed to sell lab-made chicken in Singapore and the United States. It generates shredded chicken from just 3% cultivated meat and plant-based ingredients. Aleph Farms in Rehovot, Israel, uses 3D-printing technology to combine beef muscle and fat cells to make products that look like marbled steaks, which it has approval to sell in Israel.
Growing a large slab of meat, rather than sticking chunks together, is desirable because it helps to better mimic the natural structure and texture of conventional meat. But this feat remains “one of the major challenges in the field”, says Amy Rowat, a biophysicist at the University of California, Los Angeles, who works on lab-grown meat. The cells need to continuously receive nutrients and oxygen to remain healthy and grow. In animals, blood vessels do this job, ferrying nutrients throughout tissue.
The team used a bioreactor threaded with many semipermeable, hollow fibres (shown here) in which to grow their cultured chicken.Credit: Shoji Takeuchi, The University of Tokyo",https://www.nature.com/articles/d41586-025-01227-4
